{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "4d27a39e",
        "execution_start": 1713328681005,
        "execution_millis": 8427,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "3133a9c997d54dedb35a9737ff440a4c",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1Kq2ofUi7Ks",
        "outputId": "19984725-3a81-4694-8b56-06f686b44cb0"
      },
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "88e17695",
        "execution_start": 1713328689435,
        "execution_millis": 6346,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "cda56226735b40ef9ae4de0d3838e456",
        "deepnote_cell_type": "code",
        "id": "83sSbwVwi7Kw"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "ElcIhscCmzsv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "51195742",
        "execution_start": 1713328695795,
        "execution_millis": 70021,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "2e19193073f942179901098c44d25b09",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbf5WHT0i7Kx",
        "outputId": "dcb4e867-3ff4-4827-ed8f-8c73cd6b8b98"
      },
      "source": [
        "#data from kaggle dataset: \"Prediction of music genre\"\n",
        "data1 = pd.read_csv(\"music_genre.csv\")\n",
        "#data from kaggle data set: \"Spotify Tracks Dataset\"\n",
        "data2 = pd.read_csv(\"dataset.csv\")\n",
        "\n",
        "before_drop_na = len(data1)\n",
        "data1 = data1.dropna()\n",
        "after_drop_na = len(data1)\n",
        "print(\"number of data dropped:\", before_drop_na-after_drop_na)\n",
        "\n",
        "#make key, mode into One Hot encoding\n",
        "#music_genre into label encoding\n",
        "onehot = OneHotEncoder(sparse=False)\n",
        "onehot.fit(data1[['key', 'mode']])\n",
        "onehotencoded = onehot.transform(data1[['key', 'mode']])\n",
        "categorical_columns = [f'{col}_{cat}' for i, col in enumerate(data1[['key', 'mode']].columns) for cat in onehot.categories_[i]]\n",
        "onehotdf = pd.DataFrame(onehotencoded, columns=categorical_columns)\n",
        "data1 = pd.concat([data1.reset_index(), onehotdf.reset_index()], axis=1)\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "data1['key_num'] = labelencoder.fit_transform(data1['key'])\n",
        "data1['mode_num'] = labelencoder.fit_transform(data1['mode'])\n",
        "data1['music_genre_num'] = labelencoder.fit_transform(data1['music_genre'])\n",
        "data1\n",
        "\n",
        "data1_edit = data1.drop(columns = [\"index\", \"instance_id\", \"artist_name\", \"track_name\", \"music_genre\", \"key\", \"mode\", \"tempo\", \"obtained_date\", \"key_num\", \"mode_num\", \"music_genre_num\"])\n",
        "features = data1_edit.columns\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data1_edit\n",
        "y = data1['music_genre_num']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, data1[\"music_genre\"], test_size=0.2, random_state=1)\n",
        "\n",
        "y_train_encoded = labelencoder.fit_transform(y_train)\n",
        "y_test_encoded = labelencoder.transform(y_test)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    MaxPooling1D(2),\n",
        "    Conv1D(64, 3, activation='relu'),\n",
        "    MaxPooling1D(2),\n",
        "    Conv1D(128, 3, activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(len(np.unique(y)), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train_encoded, epochs=5, batch_size=32, validation_data=(X_test, y_test_encoded))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-14def6aae7de>:4: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data2 = pd.read_csv(\"dataset.csv\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of data dropped: 6\n",
            "Epoch 1/5\n",
            "888/888 [==============================] - 11s 11ms/step - loss: 1.3332 - accuracy: 0.5048 - val_loss: 1.1724 - val_accuracy: 0.5645\n",
            "Epoch 2/5\n",
            "888/888 [==============================] - 11s 12ms/step - loss: 1.1250 - accuracy: 0.5848 - val_loss: 1.1267 - val_accuracy: 0.5869\n",
            "Epoch 3/5\n",
            "888/888 [==============================] - 8s 8ms/step - loss: 1.0876 - accuracy: 0.5969 - val_loss: 1.0859 - val_accuracy: 0.5969\n",
            "Epoch 4/5\n",
            "888/888 [==============================] - 6s 6ms/step - loss: 1.0586 - accuracy: 0.6113 - val_loss: 1.0810 - val_accuracy: 0.6022\n",
            "Epoch 5/5\n",
            "888/888 [==============================] - 5s 5ms/step - loss: 1.0377 - accuracy: 0.6149 - val_loss: 1.0515 - val_accuracy: 0.6093\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79ce2835f1c0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "97373962",
        "execution_start": 1713328765860,
        "execution_millis": 8123,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "e7af4f3641484a2f97b898810f1a8cf1",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoTgvNcpi7Kz",
        "outputId": "db9cb1fc-80d9-4520-9a84-09dede18182e"
      },
      "source": [
        "intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer('flatten').output)\n",
        "cnn_features_train = intermediate_layer_model.predict(X_train)\n",
        "cnn_features_test = intermediate_layer_model.predict(X_test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "888/888 [==============================] - 2s 2ms/step\n",
            "222/222 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost and CNN Data 1 Model"
      ],
      "metadata": {
        "id": "fo8IRBL6nKJ0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "e3da7afc",
        "execution_start": 1713328773990,
        "execution_millis": 209339,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "4528baf2cba648f7a5b6517a24c61423",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "row5SjcIi7K0",
        "outputId": "be327873-c821-4235-8c0f-939ad3c37ce8"
      },
      "source": [
        "xgb_model = xgb.XGBClassifier()\n",
        "xgb_model.fit(cnn_features_train, y_train_encoded)\n",
        "\n",
        "y_pred = xgb_model.predict(cnn_features_test)\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "\n",
        "print(\"Accuracy for Data 1:\", accuracy)\n",
        "print(\"Classification Report for Data 1:\")\n",
        "print(classification_report(y_test_encoded, y_pred))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Data 1: 0.6163167535578413\n",
            "Classification Report for Data 1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.51      0.48       962\n",
            "           1       0.78      0.78      0.78      1033\n",
            "           2       0.55      0.52      0.53       960\n",
            "           3       0.55      0.61      0.58      1021\n",
            "           4       0.64      0.61      0.63      1018\n",
            "           5       0.57      0.54      0.55      1019\n",
            "           6       0.76      0.81      0.79       977\n",
            "           7       0.07      0.01      0.02       107\n",
            "\n",
            "    accuracy                           0.62      7097\n",
            "   macro avg       0.55      0.55      0.54      7097\n",
            "weighted avg       0.61      0.62      0.61      7097\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting dataset, Standardizing features, Training data etc."
      ],
      "metadata": {
        "id": "4UMl7zs5nQEs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "a60d50f6",
        "execution_start": 1713328983332,
        "execution_millis": 195138,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "be83d0684e3f4f65ab6203bf0a21ee96",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4sEYrEQi7K0",
        "outputId": "507e2859-3365-4c93-995f-ad97bb7e7df2"
      },
      "source": [
        "data2 = data2.dropna()\n",
        "#make track_genre into label encoding\n",
        "labelencoder = LabelEncoder()\n",
        "data2['track_genre_num'] = labelencoder.fit_transform(data2['track_genre'])\n",
        "data2\n",
        "\n",
        "features2 = [\"popularity\", \"duration_ms\", \"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"time_signature\"]\n",
        "len(features2)\n",
        "\n",
        "# Separate features and target variable for data 2\n",
        "X2 = data2[features2]  # Features for data 2\n",
        "y2 = data2['track_genre_num']  # Target variable for data 2\n",
        "\n",
        "# Split the dataset into training and testing sets for data 2\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=1)\n",
        "\n",
        "y_train_encoded2 = labelencoder.fit_transform(y_train2)\n",
        "y_test_encoded2 = labelencoder.transform(y_test2)\n",
        "\n",
        "# Standardize the features for data 2\n",
        "scaler = StandardScaler()\n",
        "X_train2 = scaler.fit_transform(X_train2)\n",
        "X_test2 = scaler.transform(X_test2)\n",
        "\n",
        "# Reshape the data for CNN input for data 2\n",
        "X_train2 = X_train2.reshape(X_train2.shape[0], X_train2.shape[1], 1)\n",
        "X_test2 = X_test2.reshape(X_test2.shape[0], X_test2.shape[1], 1)\n",
        "\n",
        "# Define the CNN model for data 2\n",
        "model2 = Sequential([\n",
        "    Conv1D(32, 3, activation='relu', input_shape=(X_train2.shape[1], 1)),\n",
        "    Conv1D(64, 3, activation='relu'),\n",
        "    Conv1D(128, 3, activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(len(np.unique(y2)), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model for data 2\n",
        "model2.fit(X_train2, y_train_encoded2, epochs=5, batch_size=32, validation_data=(X_test2, y_test_encoded2))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-0f54aaaf1f32>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data2['track_genre_num'] = labelencoder.fit_transform(data2['track_genre'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1805/1805 [==============================] - 14s 7ms/step - loss: 2.9948 - accuracy: 0.2188 - val_loss: 2.6442 - val_accuracy: 0.2838\n",
            "Epoch 2/5\n",
            "1805/1805 [==============================] - 13s 7ms/step - loss: 2.5497 - accuracy: 0.3010 - val_loss: 2.5011 - val_accuracy: 0.3072\n",
            "Epoch 3/5\n",
            "1805/1805 [==============================] - 13s 7ms/step - loss: 2.4118 - accuracy: 0.3290 - val_loss: 2.3940 - val_accuracy: 0.3325\n",
            "Epoch 4/5\n",
            "1805/1805 [==============================] - 13s 7ms/step - loss: 2.3173 - accuracy: 0.3467 - val_loss: 2.3433 - val_accuracy: 0.3457\n",
            "Epoch 5/5\n",
            "1805/1805 [==============================] - 13s 7ms/step - loss: 2.2400 - accuracy: 0.3650 - val_loss: 2.3318 - val_accuracy: 0.3458\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79ce27edf1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "712e514e",
        "execution_start": 1713329394879,
        "execution_millis": 20281,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "e1258a0c68d947e7b91e3df2e30043f9",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw6q-SBQi7K1",
        "outputId": "554d3221-053d-41b6-c2e8-a7c2ed11bc97"
      },
      "source": [
        "intermediate_layer_model2 = Model(inputs=model2.input, outputs=model2.get_layer('flatten_1').output)\n",
        "cnn_features_train2 = intermediate_layer_model2.predict(X_train2)\n",
        "cnn_features_test2 = intermediate_layer_model2.predict(X_test2)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1805/1805 [==============================] - 4s 2ms/step\n",
            "452/452 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data 2 Model"
      ],
      "metadata": {
        "id": "PoJctafZnquM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "78abee13",
        "execution_start": 1713329422844,
        "execution_millis": 0,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "31211386b2544abab30ddb1cd8c4cf8c",
        "deepnote_cell_type": "code",
        "id": "-hTS1vpai7K1"
      },
      "source": [
        "xgb_model = xgb.XGBClassifier(n_jobs=-1)\n",
        "xgb_model.fit(cnn_features_train2, y_train_encoded2)\n",
        "\n",
        "y_pred2 = xgb_model.predict(cnn_features_test2)\n",
        "accuracy2 = accuracy_score(y_test_encoded2, y_pred2)\n",
        "\n",
        "print(\"Accuracy for Data 2:\", accuracy2)\n",
        "print(\"Classification Report for Data 2:\")\n",
        "print(classification_report(y_test_encoded2, y_pred2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3da032f1-e5ab-4726-ac09-eb3d9c053730' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ],
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown",
        "id": "ClrLYTW5i7K2"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote_notebook_id": "da3226f8972641fda18a4dfa25c61d0b",
    "deepnote_execution_queue": [],
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  }
}